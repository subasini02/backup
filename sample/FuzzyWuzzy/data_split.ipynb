{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Function to write data to CSV file\n",
    "def write_to_csv(filename, data, headers=None):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if headers:\n",
    "            writer.writerow(headers)\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Read the data from the original CSV file\n",
    "with open('C:/Users/subasini/Downloads/agg_response/agg_response.csv', newline='', encoding='latin-1') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=',')\n",
    "\n",
    "    # Initialize lists to store data for each CSV file\n",
    "    csv1_data = []\n",
    "    csv2_data = []\n",
    "\n",
    "    for row in reader:\n",
    "        # Extract data for first CSV file\n",
    "        csv1_row = [row['loc_id'], row['loc_name'], row['aggr_order_channel'], row['aggr_full_name']]\n",
    "        csv1_data.append(csv1_row)\n",
    "\n",
    "        # Extract data for second CSV file\n",
    "        csv2_row = [row['channel'], row['full_name'], row['loc_id'], row['loc_name'], row['maghil_phone']]\n",
    "        csv2_data.append(csv2_row)\n",
    "\n",
    "# Write data to respective CSV files with headers\n",
    "csv1_headers = ['loc_id', 'loc_name', 'aggr_order_channel', 'aggr_full_name']\n",
    "write_to_csv('./agg_details.csv', csv1_data, headers=csv1_headers)\n",
    "\n",
    "csv2_headers = [ 'channel', 'full_name', 'loc_id', 'loc_name','maghil_phone']\n",
    "write_to_csv('./details.csv', csv2_data, headers=csv2_headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Function to write data to CSV file\n",
    "def write_to_csv(filename, data, headers=None):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if headers:\n",
    "            writer.writerow(headers)\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Read the data from the original CSV file\n",
    "with open('./details.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    data = [row for row in reader]\n",
    "\n",
    "# Filter data for \"A2B Princeton\" location\n",
    "filtered_data = [row for row in data if row[3] == 'A2B Princeton']  # Assuming 'A2B Princeton' is at index 3 in loc_name\n",
    "csv2_headers = [ 'channel', 'full_name','loc_id', 'loc_name', 'maghil_phone']\n",
    "\n",
    "# Write filtered data to a new CSV file\n",
    "write_to_csv('./filtered_data.csv', filtered_data, headers=csv2_headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Function to write data to CSV file\n",
    "def write_to_csv(filename, data, headers=None):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if headers:\n",
    "            writer.writerow(headers)\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Read the data from the original CSV file\n",
    "with open('./agg_details.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    data = [row for row in reader]\n",
    "\n",
    "# Filter data for \"A2B Parsippany\" location and \"UberEats\" channel\n",
    "filtered_data = [row for row in data if row[1] == 'A2B Princeton'] \n",
    "\n",
    "csv1_headers = ['loc_id', 'loc_name', 'aggr_order_channel', 'aggr_full_name'] \n",
    "\n",
    "# Write filtered data to a new CSV file\n",
    "write_to_csv('./agg_filtered_data.csv', filtered_data,headers=csv1_headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Function to write data to CSV file\n",
    "def write_to_csv(filename, data, headers=None):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if headers:\n",
    "            writer.writerow(headers)\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Read the data from the original CSV file\n",
    "with open('C:/Users/subasini/Downloads/agg_response/agg_response.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    data = [row for row in reader]\n",
    "\n",
    "# Filter data for \"A2B Princeton\" location\n",
    "filtered_data = [row for row in data if row[1] == 'A2B Warrenville']  # Assuming 'A2B Princeton' is at index 3 in loc_name\n",
    "csv2_headers = [\"loc_id\",\"loc_name\",\t\"aggr_order_channel\",\t\"aggr_full_name\",\t\"aggr_soundex_score\",\t\"channel\",\t\"full_name\",\t\"magil_soundex_score\",\t\"maghil_phone\"\t,\"match_score\"]\n",
    "\n",
    "# Write filtered data to a new CSV file\n",
    "write_to_csv('./filtered_data_4.csv', filtered_data, headers=csv2_headers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>loc_name</th>\n",
       "      <th>aggr_order_channel</th>\n",
       "      <th>aggr_full_name</th>\n",
       "      <th>aggr_soundex_score</th>\n",
       "      <th>channel</th>\n",
       "      <th>full_name</th>\n",
       "      <th>magil_soundex_score</th>\n",
       "      <th>maghil_phone</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Parsippany</td>\n",
       "      <td>UberEats</td>\n",
       "      <td>Abhishek S.</td>\n",
       "      <td>A120</td>\n",
       "      <td>Maghil</td>\n",
       "      <td>ABHISHEK</td>\n",
       "      <td>A120</td>\n",
       "      <td>-6292439194</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Parsippany</td>\n",
       "      <td>UberEats</td>\n",
       "      <td>Abhishek S.</td>\n",
       "      <td>A120</td>\n",
       "      <td>Maghil</td>\n",
       "      <td>Abhisek</td>\n",
       "      <td>A120</td>\n",
       "      <td>-9736416575</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Parsippany</td>\n",
       "      <td>UberEats</td>\n",
       "      <td>Abhishek S.</td>\n",
       "      <td>A120</td>\n",
       "      <td>Maghil</td>\n",
       "      <td>Abhishek chaki</td>\n",
       "      <td>A120</td>\n",
       "      <td>-6462484858</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Parsippany</td>\n",
       "      <td>UberEats</td>\n",
       "      <td>Abhishek S.</td>\n",
       "      <td>A120</td>\n",
       "      <td>Maghil</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>A120</td>\n",
       "      <td>-2012204715</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Parsippany</td>\n",
       "      <td>UberEats</td>\n",
       "      <td>Abhishek S.</td>\n",
       "      <td>A120</td>\n",
       "      <td>Maghil</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>A120</td>\n",
       "      <td>-9734243785</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Parsippany</td>\n",
       "      <td>UberEats</td>\n",
       "      <td>Abhishek S.</td>\n",
       "      <td>A120</td>\n",
       "      <td>Maghil</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>A120</td>\n",
       "      <td>-8122518367</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Parsippany</td>\n",
       "      <td>UberEats</td>\n",
       "      <td>Abhishek S.</td>\n",
       "      <td>A120</td>\n",
       "      <td>Maghil</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>A120</td>\n",
       "      <td>-3478795119</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Parsippany</td>\n",
       "      <td>UberEats</td>\n",
       "      <td>Abhishek S.</td>\n",
       "      <td>A120</td>\n",
       "      <td>Maghil</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>A120</td>\n",
       "      <td>-3053336759</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Parsippany</td>\n",
       "      <td>UberEats</td>\n",
       "      <td>Abhishek S.</td>\n",
       "      <td>A120</td>\n",
       "      <td>Maghil</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>A120</td>\n",
       "      <td>-2016831629</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Parsippany</td>\n",
       "      <td>UberEats</td>\n",
       "      <td>Abhishek S.</td>\n",
       "      <td>A120</td>\n",
       "      <td>Maghil</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>A120</td>\n",
       "      <td>-8122722353</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 loc_id        loc_name aggr_order_channel  \\\n",
       "0  14d293a8-81c5-40b2-a208-be1c03a93fad  A2B Parsippany           UberEats   \n",
       "1  14d293a8-81c5-40b2-a208-be1c03a93fad  A2B Parsippany           UberEats   \n",
       "2  14d293a8-81c5-40b2-a208-be1c03a93fad  A2B Parsippany           UberEats   \n",
       "3  14d293a8-81c5-40b2-a208-be1c03a93fad  A2B Parsippany           UberEats   \n",
       "4  14d293a8-81c5-40b2-a208-be1c03a93fad  A2B Parsippany           UberEats   \n",
       "5  14d293a8-81c5-40b2-a208-be1c03a93fad  A2B Parsippany           UberEats   \n",
       "6  14d293a8-81c5-40b2-a208-be1c03a93fad  A2B Parsippany           UberEats   \n",
       "7  14d293a8-81c5-40b2-a208-be1c03a93fad  A2B Parsippany           UberEats   \n",
       "8  14d293a8-81c5-40b2-a208-be1c03a93fad  A2B Parsippany           UberEats   \n",
       "9  14d293a8-81c5-40b2-a208-be1c03a93fad  A2B Parsippany           UberEats   \n",
       "\n",
       "  aggr_full_name aggr_soundex_score channel       full_name  \\\n",
       "0    Abhishek S.               A120  Maghil        ABHISHEK   \n",
       "1    Abhishek S.               A120  Maghil         Abhisek   \n",
       "2    Abhishek S.               A120  Maghil  Abhishek chaki   \n",
       "3    Abhishek S.               A120  Maghil        Abhishek   \n",
       "4    Abhishek S.               A120  Maghil        Abhishek   \n",
       "5    Abhishek S.               A120  Maghil        Abhishek   \n",
       "6    Abhishek S.               A120  Maghil        Abhishek   \n",
       "7    Abhishek S.               A120  Maghil        Abhishek   \n",
       "8    Abhishek S.               A120  Maghil        Abhishek   \n",
       "9    Abhishek S.               A120  Maghil        Abhishek   \n",
       "\n",
       "  magil_soundex_score  maghil_phone match_score  \n",
       "0                A120   -6292439194         Low  \n",
       "1                A120   -9736416575         Low  \n",
       "2                A120   -6462484858         Low  \n",
       "3                A120   -2012204715         Low  \n",
       "4                A120   -9734243785         Low  \n",
       "5                A120   -8122518367         Low  \n",
       "6                A120   -3478795119         Low  \n",
       "7                A120   -3053336759         Low  \n",
       "8                A120   -2016831629         Low  \n",
       "9                A120   -8122722353         Low  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "org_data = pd.read_csv('C:/Users/subasini/Downloads/agg_response/agg_response.csv',encoding='latin-1')\n",
    "\n",
    "org_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "agg_data = pd.read_csv('./filtered_data_4.csv',encoding='latin-1')\n",
    "\n",
    "len(agg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agg Filtered (A2B Princeton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>loc_name</th>\n",
       "      <th>aggr_order_channel</th>\n",
       "      <th>aggr_full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Princeton</td>\n",
       "      <td>Grubhub</td>\n",
       "      <td>Ashish B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Princeton</td>\n",
       "      <td>GrubHub</td>\n",
       "      <td>Bhanu T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Princeton</td>\n",
       "      <td>Uber Eats</td>\n",
       "      <td>Claire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Princeton</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>Guru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Princeton</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>Guru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Princeton</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>Guru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Princeton</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>Guru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Princeton</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>Guru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Princeton</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>Guru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22d293a8-81c5-40b2-a208-be1c03a93fad</td>\n",
       "      <td>A2B Princeton</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>Guru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 loc_id       loc_name aggr_order_channel  \\\n",
       "0  22d293a8-81c5-40b2-a208-be1c03a93fad  A2B Princeton            Grubhub   \n",
       "1  22d293a8-81c5-40b2-a208-be1c03a93fad  A2B Princeton            GrubHub   \n",
       "2  22d293a8-81c5-40b2-a208-be1c03a93fad  A2B Princeton          Uber Eats   \n",
       "3  22d293a8-81c5-40b2-a208-be1c03a93fad  A2B Princeton           DoorDash   \n",
       "4  22d293a8-81c5-40b2-a208-be1c03a93fad  A2B Princeton           DoorDash   \n",
       "5  22d293a8-81c5-40b2-a208-be1c03a93fad  A2B Princeton           DoorDash   \n",
       "6  22d293a8-81c5-40b2-a208-be1c03a93fad  A2B Princeton           DoorDash   \n",
       "7  22d293a8-81c5-40b2-a208-be1c03a93fad  A2B Princeton           DoorDash   \n",
       "8  22d293a8-81c5-40b2-a208-be1c03a93fad  A2B Princeton           DoorDash   \n",
       "9  22d293a8-81c5-40b2-a208-be1c03a93fad  A2B Princeton           DoorDash   \n",
       "\n",
       "  aggr_full_name  \n",
       "0       Ashish B  \n",
       "1        Bhanu T  \n",
       "2         Claire  \n",
       "3           Guru  \n",
       "4           Guru  \n",
       "5           Guru  \n",
       "6           Guru  \n",
       "7           Guru  \n",
       "8           Guru  \n",
       "9           Guru  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "agg_data = pd.read_csv('./agg_filtered_data.csv',encoding='latin-1')\n",
    "\n",
    "agg_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered A2B Princeton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filt_data = pd.read_csv('./filtered_data_2.csv',encoding='latin-1')\n",
    "\n",
    "len(filt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping After Filtering and Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subasini\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11763"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filt_data = pd.read_csv('./csv/merged_data.csv',encoding='latin-1')\n",
    "len(filt_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
